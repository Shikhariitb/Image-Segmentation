{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This colab notebook is based on the tutorial for semantic image segmentation of images containing people. It involves U-net architecture.\n",
        "\n",
        "The original paper on U-net architecture https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
        "\n",
        "The link for youtube video I referred for the same - https://youtu.be/azM57JuQpQI"
      ],
      "metadata": {
        "id": "qLFDlOgCIj72"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74De-UAVgeH0"
      },
      "outputs": [],
      "source": [
        "from re import I\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image parameters and dataset path"
      ],
      "metadata": {
        "id": "wSf3LCT8J2h5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path_img = \"./../Downloads/Human-Segmentation-Dataset-master/Training_Images/\"\n",
        "images = next(os.walk(dir_path_img))[2]\n",
        "dir_path_msk = \"./../Downloads/Human-Segmentation-Dataset-master/Ground_Truth/\"\n",
        "masks = next(os.walk(dir_path_msk))[2]\n",
        "\n",
        "# image properties\n",
        "img_width = 128\n",
        "img_height = 128\n",
        "img_channels = 3"
      ],
      "metadata": {
        "id": "VunMmuNtgp1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing the images and preparing the sample input and output"
      ],
      "metadata": {
        "id": "kwyXW6zqJ9en"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = np.zeros((len(images), img_height, img_width, img_channels), dtype = np.uint8)\n",
        "msks = np.zeros((len(images), img_height, img_width, 1), dtype = bool)\n",
        "\n",
        "# image resizing\n",
        "for i in range(1, len(images) + 1):\n",
        "    s = str(i)\n",
        "    img = imread(dir_path_img + s + \".jpg\")\n",
        "    img = resize(img, (img_height, img_width, img_channels), mode = 'constant', preserve_range = True)\n",
        "    imgs[i - 1] = img\n",
        "    msk = np.zeros((img_height, img_width, 1), dtype = bool)\n",
        "    msk1 = imread(dir_path_msk + s + \".png\")\n",
        "    msk1 = np.expand_dims(resize(msk1, (img_height, img_width), mode = 'constant', preserve_range = True), axis = -1)\n",
        "    msks[i - 1] = np.maximum(msk, msk1)"
      ],
      "metadata": {
        "id": "aW05jTswgu0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The U-net architecture"
      ],
      "metadata": {
        "id": "8g3Rz-VkKMh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input layer\n",
        "inp_img = tf.keras.layers.Input((img_height, img_width, img_channels))\n",
        "inputs = tf.keras.layers.Lambda(lambda x: x/255)(inp_img)\n",
        "\n",
        "# convolutional and max pooling layers of contraction path\n",
        "cl1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(inputs)\n",
        "cl1 = tf.keras.layers.Dropout(0.1)(cl1)\n",
        "cl1 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl1)\n",
        "pl1 = tf.keras.layers.MaxPooling2D((2,2))(cl1)\n",
        "\n",
        "cl2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(pl1)\n",
        "cl2 = tf.keras.layers.Dropout(0.1)(cl2)\n",
        "cl2 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl2)\n",
        "pl2 = tf.keras.layers.MaxPooling2D((2,2))(cl2)\n",
        "\n",
        "cl3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(pl2)\n",
        "cl3 = tf.keras.layers.Dropout(0.2)(cl3)\n",
        "cl3 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl3)\n",
        "pl3 = tf.keras.layers.MaxPooling2D((2,2))(cl3)\n",
        "\n",
        "cl4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(pl3)\n",
        "cl4 = tf.keras.layers.Dropout(0.2)(cl4)\n",
        "cl4 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl4)\n",
        "pl4 = tf.keras.layers.MaxPooling2D((2,2))(cl4)\n",
        "\n",
        "cl5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(pl4)\n",
        "cl5 = tf.keras.layers.Dropout(0.3)(cl5)\n",
        "cl5 = tf.keras.layers.Conv2D(256, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl5)\n",
        "\n",
        "# expansive path\n",
        "ul6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides = (2,2), padding = 'same')(cl5)\n",
        "ul6 = tf.keras.layers.concatenate([ul6,cl4])\n",
        "cl6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(ul6)\n",
        "cl6 = tf.keras.layers.Dropout(0.2)(cl6)\n",
        "cl6 = tf.keras.layers.Conv2D(128, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl6)\n",
        "\n",
        "ul7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides = (2,2), padding = 'same')(cl6)\n",
        "ul7 = tf.keras.layers.concatenate([ul7,cl3])\n",
        "cl7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(ul7)\n",
        "cl7 = tf.keras.layers.Dropout(0.2)(cl7)\n",
        "cl7 = tf.keras.layers.Conv2D(64, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl7)\n",
        "\n",
        "ul8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides = (2,2), padding = 'same')(cl7)\n",
        "ul8 = tf.keras.layers.concatenate([ul8,cl2])\n",
        "cl8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(ul8)\n",
        "cl8 = tf.keras.layers.Dropout(0.1)(cl8)\n",
        "cl8 = tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl8)\n",
        "\n",
        "ul9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides = (2,2), padding = 'same')(cl8)\n",
        "ul9 = tf.keras.layers.concatenate([ul9,cl1])\n",
        "cl9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(ul9)\n",
        "cl9 = tf.keras.layers.Dropout(0.1)(cl9)\n",
        "cl9 = tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', kernel_initializer = 'he_normal', padding = 'same')(cl9)\n",
        "\n",
        "outputs = tf.keras.layers.Conv2D(1, (1, 1), activation = 'sigmoid')(cl9)\n",
        "model = tf.keras.Model(inputs = [inputs], outputs = [outputs])\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "YfAImTA_gyf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model checkpin\n",
        "cp = tf.keras.callbacks.ModelCheckpoint('img_seg.h5', verbose = 1, save_best_only = True)\n",
        "# callbacks\n",
        "callbacks = [\n",
        "    #tf.keras.callbacks.EarlyStopping(patience = 2, monitor = 'val_loss'),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir = 'logs')\n",
        "]"
      ],
      "metadata": {
        "id": "ViajgG_Fg33D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(imgs, msks, validation_split = 0.1, batch_size = 16, epochs = 100, callbacks = callbacks)"
      ],
      "metadata": {
        "id": "uZAM9nV6g8Wh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}